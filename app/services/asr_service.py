# app/services/asr_service.py

import io
import torch
import whisper
import webrtcvad
import numpy as np
from pydub import AudioSegment
from app.core.config import ASR_MODEL
from app.core.logger import get_logger

logger = get_logger(__name__)

# âš™ï¸ Cáº¥u hÃ¬nh FFmpeg
try:
    AudioSegment.converter = "C:/ProgramData/chocolatey/bin/ffmpeg.exe"
    AudioSegment.ffprobe   = "C:/ProgramData/chocolatey/bin/ffprobe.exe"
    logger.info("âœ… FFmpeg configured for Pydub.")
except Exception:
    logger.error("âŒ FFmpeg not found! Check installation path.")

class ASRService:
    def __init__(self):
        """Khá»Ÿi táº¡o mÃ´ hÃ¬nh Whisper + VAD."""
        logger.info(f"ðŸ”Š Loading Whisper ASR model: {ASR_MODEL} ...")
        try:
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self.model = whisper.load_model(ASR_MODEL, device=device)
            self.vad = webrtcvad.Vad(mode=2)
            logger.info(f"âœ… Whisper model '{ASR_MODEL}' loaded on {device}.")
        except Exception as e:
            logger.error(f"âŒ Failed to load Whisper model: {e}", exc_info=True)
            raise

    def transcribe(self, audio_bytes: bytes) -> str:
        """Nháº­n bytes Ã¢m thanh (WAV hoáº·c WebM) â†’ text tiáº¿ng Viá»‡t."""
        if not isinstance(audio_bytes, bytes) or len(audio_bytes) < 2000:
            logger.warning(f"âš ï¸ Invalid or too short audio: {len(audio_bytes)} bytes.")
            return ""

        try:
            # ðŸ§© Cá»‘ Ä‘á»c theo thá»© tá»±: WAV â†’ WebM
            try:
                audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes), format="wav")
                logger.info("âœ… Äá»c thÃ nh cÃ´ng file WAV.")
            except Exception as e_wav:
                logger.warning(f"âš ï¸ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c WAV ({e_wav}), thá»­ WebM...")
                try:
                    audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes), format="webm")
                    logger.info("âœ… Äá»c thÃ nh cÃ´ng file WebM.")
                except Exception as e_webm:
                    logger.error(f"âŒ KhÃ´ng thá»ƒ Ä‘á»c audio (WAV/WebM): {e_webm}", exc_info=True)
                    return "Lá»—i Ä‘á»‹nh dáº¡ng Ã¢m thanh (khÃ´ng Ä‘á»c Ä‘Æ°á»£c)."

            # Chuáº©n hÃ³a: 16kHz mono PCM
            audio_segment = audio_segment.set_frame_rate(16000).set_channels(1).set_sample_width(2)
            pcm_data = audio_segment.raw_data

            # Voice Activity Detection
            frame_ms = 30
            frame_bytes = int(16000 * frame_ms / 1000) * 2
            frames = [
                pcm_data[i:i + frame_bytes]
                for i in range(0, len(pcm_data), frame_bytes)
                if len(pcm_data[i:i + frame_bytes]) == frame_bytes
                and self.vad.is_speech(pcm_data[i:i + frame_bytes], 16000)
            ]

            if not frames:
                logger.warning("âš ï¸ VAD khÃ´ng phÃ¡t hiá»‡n giá»ng nÃ³i. DÃ¹ng toÃ n bá»™ audio.")
                frames = [pcm_data]

            trimmed_pcm = b"".join(frames)
            audio_np = np.frombuffer(trimmed_pcm, dtype=np.int16).astype(np.float32) / 32768.0
            duration = len(audio_np) / 16000

            logger.info(f"ðŸ§  Nháº­n dáº¡ng giá»ng nÃ³i ({duration:.2f}s)...")
            result = self.model.transcribe(audio_np, language="vi", fp16=torch.cuda.is_available())
            text = result.get("text", "").strip()
            logger.info(f"âœ… Káº¿t quáº£ ASR: â€œ{text}â€")

            return text or "KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c giá»ng nÃ³i."

        except Exception as e:
            logger.error(f"âŒ Lá»—i khi xá»­ lÃ½ nháº­n dáº¡ng: {e}", exc_info=True)
            return "Lá»—i há»‡ thá»‘ng nháº­n dáº¡ng giá»ng nÃ³i."

# Instance toÃ n cá»¥c
asr_service = ASRService()
